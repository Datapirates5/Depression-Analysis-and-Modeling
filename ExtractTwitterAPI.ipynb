{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25df340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "consumer_key = 'ArMTh2jwpVVS79pNvRcR83tcX'\n",
    "consumer_secret = 'pmDqMVaffM0ZycctKP2PgM7wjrgrS1J6AlwYtyCYuu4Yms9YxV'\n",
    "access_token= '1504127199690981379-wnf9WWt7G4AOgC4AxyHxi38yWHwMaf'\n",
    "access_token_secret = 'GjdP7ffL6RzhWRyUWQuQ2EJOKYVbl4dUUYvSmpTZ1GI29'\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAABdHaQEAAAAAlShP865KdOBA0cci77vd%2FO2whp8%3DJqAEa1rSRKUsgqh3hfNV1wAGtCothvH2BGH89N1onmTnp2U87t'\n",
    "\n",
    "client = tweepy.Client(consumer_key= consumer_key,consumer_secret= consumer_secret,access_token= access_token,access_token_secret= access_token_secret, bearer_token = bearer_token)\n",
    "\n",
    "# query to search for tweets\n",
    "query = \"depression lang:en -is:retweet\"\n",
    "\n",
    "# your start and end time for fetching tweets\n",
    "start_time = \"2022-04-03T00:00:00Z\"\n",
    "#end_time = \"2022-04-02T00:00:00Z\"\n",
    "\n",
    "end_time = {'1':'2022-04-08T00:00:00Z','2':'2022-04-08T00:30:00Z', '3':'2022-04-08T01:00:00Z', '4':'2022-04-08T01:30:00Z', \n",
    "            '5':'2022-04-08T02:00:00Z','6':'2022-04-08T02:30:00Z', '7':'2022-04-08T03:00:00Z',\n",
    "            '8':'2022-04-08T03:30:00Z','9':'2022-04-08T04:00:00Z', '10':'2022-04-08T04:30:00Z', '11':'2022-04-08T05:00:00Z',\n",
    "            '12':'2022-04-08T05:30:00Z', '13':'2022-04-08T06:00:00Z', '14':'2022-04-08T06:30:00Z',\n",
    "            '15':'2022-04-08T07:00:00Z','16':'2022-04-08T07:30:00Z', '17':'2022-04-08T08:00:00Z',\n",
    "            '18':'2022-04-08T08:30:00Z', '19':'2022-04-08T09:00:00Z', '20':'2022-04-08T09:30:00Z', '21':'2022-04-08T10:00:00Z',\n",
    "            '22':'2022-04-08T10:30:00Z', '23':'2022-04-08T11:00:00Z', '24':'2022-04-08T11:30:00Z', '25':'2022-04-08T12:00:00Z',\n",
    "            '26':'2022-04-08T12:30:00Z', '27':'2022-04-08T13:00:00Z', '28':'2022-04-08T13:30:00Z', '29':'2022-04-08T14:00:00Z',\n",
    "            '30':'2022-04-08T14:30:00Z', '31':'2022-04-08T15:00:00Z', '32':'2022-04-08T15:30:00Z', '33':'2022-04-08T16:00:00Z',\n",
    "            '34':'2022-04-08T16:30:00Z', '35':'2022-04-08T17:00:00Z','36':'2022-04-08T17:30:00Z', '37':'2022-04-08T18:00:00Z',\n",
    "            '38':'2022-04-08T18:30:00Z', '39':'2022-04-08T19:00:00Z', '40':'2022-04-08T19:30:00Z', '41':'2022-04-08T20:00:00Z',\n",
    "            '42':'2022-04-08T20:30:00Z', '43':'2022-04-08T21:00:00Z', '44':'2022-04-08T21:30:00Z', '45':'2022-04-08T22:00:00Z',\n",
    "            '46':'2022-04-08T22:30:00Z', '47':'2022-04-08T23:00:00Z', '48':'2022-04-08T23:30:00Z',\n",
    "            '49':'2022-04-04T00:00:00Z','50':'2022-04-04T00:30:00Z', '51':'2022-04-04T01:00:00Z', '52':'2022-04-04T01:30:00Z', \n",
    "            '53':'2022-04-04T02:00:00Z','54':'2022-04-04T02:30:00Z', '55':'2022-04-04T03:00:00Z',\n",
    "            '56':'2022-04-04T04:00:00Z', '57':'2022-04-04T04:30:00Z', '58':'2022-04-04T05:00:00Z',\n",
    "            '59':'2022-04-04T05:30:00Z', '60':'2022-04-04T06:00:00Z', '61':'2022-04-04T06:30:00Z',\n",
    "            '62':'2022-04-04T07:00:00Z','63':'2022-04-04T07:30:00Z', '64':'2022-04-04T08:00:00Z',\n",
    "            '65':'2022-04-04T08:30:00Z', '66':'2022-04-04T09:00:00Z', '67':'2022-04-04T09:30:00Z', '21':'2022-04-04T10:00:00Z',\n",
    "            '68':'2022-04-04T10:30:00Z', '69':'2022-04-04T11:00:00Z', '70':'2022-04-04T11:30:00Z', '71':'2022-04-04T12:00:00Z',\n",
    "            '72':'2022-04-04T12:30:00Z', '73':'2022-04-04T13:00:00Z', '74':'2022-04-04T13:30:00Z', '75':'2022-04-04T14:00:00Z',\n",
    "            '76':'2022-04-04T14:30:00Z', '77':'2022-04-04T15:00:00Z', '78':'2022-04-04T15:30:00Z', '79':'2022-04-04T16:00:00Z',\n",
    "            '80':'2022-04-04T16:30:00Z', '81':'2022-04-04T17:00:00Z','82':'2022-04-04T17:30:00Z', '83':'2022-04-04T18:00:00Z',\n",
    "            '84':'2022-04-04T18:30:00Z', '85':'2022-04-04T19:00:00Z', '86':'2022-04-04T19:30:00Z', '87':'2022-04-04T20:00:00Z',\n",
    "            '88':'2022-04-04T20:30:00Z', '89':'2022-04-04T21:00:00Z', '90':'2022-04-04T21:30:00Z', '91':'2022-04-04T22:00:00Z',\n",
    "            '92':'2022-04-04T22:30:00Z', '93':'2022-04-04T23:00:00Z', '94':'2022-04-04T23:30:00Z',\n",
    "            '95':'2022-04-07T00:00:00Z','96':'2022-04-07T00:30:00Z', '97':'2022-04-07T01:00:00Z', '98':'2022-04-07T01:30:00Z', \n",
    "            '99':'2022-04-07T02:00:00Z','100':'2022-04-07T02:30:00Z', '101':'2022-04-07T03:00:00Z',\n",
    "            '102':'2022-04-07T03:30:00Z','103':'2022-04-07T04:00:00Z', '104':'2022-04-07T04:30:00Z', '105':'2022-04-07T05:00:00Z',\n",
    "            '106':'2022-04-07T05:30:00Z', '107':'2022-04-07T06:00:00Z', '108':'2022-04-07T06:30:00Z',\n",
    "            '109':'2022-04-07T07:00:00Z','110':'2022-04-07T07:30:00Z', '111':'2022-04-07T08:00:00Z',\n",
    "            '112':'2022-04-07T08:30:00Z', '113':'2022-04-07T09:00:00Z', '114':'2022-04-07T09:30:00Z', '115':'2022-04-07T10:00:00Z',\n",
    "            '116':'2022-04-07T10:30:00Z', '117':'2022-04-07T11:00:00Z', '118':'2022-04-07T11:30:00Z', '119':'2022-04-07T12:00:00Z',\n",
    "            '120':'2022-04-07T12:30:00Z', '121':'2022-04-07T13:00:00Z', '122':'2022-04-07T13:30:00Z', '123':'2022-04-07T14:00:00Z',\n",
    "            '124':'2022-04-07T14:30:00Z', '125':'2022-04-07T15:00:00Z', '126':'2022-04-07T15:30:00Z', '127':'2022-04-07T16:00:00Z',\n",
    "            '128':'2022-04-07T16:30:00Z', '129':'2022-04-07T17:00:00Z','130':'2022-04-07T17:30:00Z', '131':'2022-04-07T18:00:00Z',\n",
    "            '132':'2022-04-07T18:30:00Z', '133':'2022-04-07T19:00:00Z', '134':'2022-04-07T19:30:00Z', '135':'2022-04-07T20:00:00Z',\n",
    "            '136':'2022-04-07T20:30:00Z', '137':'2022-04-07T21:00:00Z', '138':'2022-04-07T21:30:00Z', '139':'2022-04-07T22:00:00Z',\n",
    "            '140':'2022-04-07T22:30:00Z', '141':'2022-04-07T23:00:00Z', '142':'2022-04-07T23:30:00Z',\n",
    "            '143':'2022-04-06T00:00:00Z','144':'2022-04-06T00:30:00Z', '145':'2022-04-06T01:00:00Z', '146':'2022-04-06T01:30:00Z', \n",
    "            '147':'2022-04-06T02:00:00Z','148':'2022-04-06T02:30:00Z', '149':'2022-04-06T03:00:00Z',\n",
    "            '150':'2022-04-06T03:30:00Z','151':'2022-04-09T03:30:00Z','152':'2022-04-06T04:00:00Z', '153':'2022-04-06T04:30:00Z', '58':'2022-04-06T05:00:00Z',\n",
    "            '154':'2022-04-06T05:30:00Z', '155':'2022-04-06T06:00:00Z', '156':'2022-04-06T06:30:00Z',\n",
    "            '157':'2022-04-06T07:00:00Z','158':'2022-04-06T07:30:00Z', '159':'2022-04-06T08:00:00Z',\n",
    "            '160':'2022-04-06T08:30:00Z', '161':'2022-04-06T09:00:00Z', '162':'2022-04-06T09:30:00Z', '163':'2022-04-06T10:00:00Z',\n",
    "            '164':'2022-04-06T10:30:00Z', '165':'2022-04-06T11:00:00Z', '166':'2022-04-06T11:30:00Z', '167':'2022-04-06T12:00:00Z',\n",
    "            '168':'2022-04-06T12:30:00Z', '169':'2022-04-06T13:00:00Z', '170':'2022-04-06T13:30:00Z', '171':'2022-04-06T14:00:00Z',\n",
    "            '172':'2022-04-06T14:30:00Z', '173':'2022-04-06T15:00:00Z', '174':'2022-04-06T15:30:00Z', '175':'2022-04-06T16:00:00Z',\n",
    "            '176':'2022-04-06T16:30:00Z', '177':'2022-04-06T17:00:00Z','178':'2022-04-06T17:30:00Z', '179':'2022-04-06T18:00:00Z',\n",
    "            '180':'2022-04-06T18:30:00Z', '181':'2022-04-06T19:00:00Z', '182':'2022-04-06T19:30:00Z', '183':'2022-04-06T20:00:00Z',\n",
    "            '184':'2022-04-06T20:30:00Z', '185':'2022-04-06T21:00:00Z', '186':'2022-04-06T21:30:00Z', '187':'2022-04-06T22:00:00Z',\n",
    "            '188':'2022-04-06T22:30:00Z', '189':'2022-04-06T23:00:00Z', '190':'2022-04-06T23:30:00Z',\n",
    "            '191':'2022-04-05T00:00:00Z','192':'2022-04-05T00:30:00Z', '193':'2022-04-05T01:00:00Z', '194':'2022-04-07T01:30:00Z', \n",
    "            '99':'2022-04-05T02:00:00Z','100':'2022-04-05T02:30:00Z', '101':'2022-04-05T03:00:00Z',\n",
    "            '195':'2022-04-05T03:30:00Z','196':'2022-04-05T04:00:00Z', '197':'2022-04-05T04:30:00Z', '198':'2022-04-07T05:00:00Z',\n",
    "            '199':'2022-04-05T05:30:00Z', '200':'2022-04-05T06:00:00Z', '201':'2022-04-05T06:30:00Z',\n",
    "            '202':'2022-04-05T07:00:00Z','203':'2022-04-05T07:30:00Z', '204':'2022-04-05T08:00:00Z',\n",
    "            '205':'2022-04-05T08:30:00Z', '206':'2022-04-05T09:00:00Z', '207':'2022-04-05T09:30:00Z', '208':'2022-04-05T10:00:00Z',\n",
    "            '209':'2022-04-05T10:30:00Z', '210':'2022-04-05T11:00:00Z', '211':'2022-04-05T11:30:00Z', '212':'2022-04-05T12:00:00Z',\n",
    "            '213':'2022-04-05T12:30:00Z', '214':'2022-04-05T13:00:00Z', '215':'2022-04-05T13:30:00Z', '216':'2022-04-05T14:00:00Z',\n",
    "            '217':'2022-04-05T14:30:00Z', '218':'2022-04-05T15:00:00Z', '219':'2022-04-05T15:30:00Z', '220':'2022-04-05T16:00:00Z',\n",
    "            '221':'2022-04-05T16:30:00Z', '222':'2022-04-05T17:00:00Z','223':'2022-04-05T17:30:00Z', '224':'2022-04-05T18:00:00Z',\n",
    "            '225':'2022-04-05T18:30:00Z', '226':'2022-04-05T19:00:00Z', '227':'2022-04-05T19:30:00Z', '228':'2022-04-05T20:00:00Z',\n",
    "            '229':'2022-04-05T20:30:00Z', '230':'2022-04-05T21:00:00Z', '231':'2022-04-05T21:30:00Z', '232':'2022-04-05T22:00:00Z',\n",
    "            '233':'2022-04-05T22:30:00Z', '234':'2022-04-05T23:00:00Z', '235':'2022-04-05T23:30:00Z',\n",
    "           }\n",
    "\n",
    "\n",
    "with open('tweets_py.csv', 'a', encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['created_at', 'text','source','name','username','location','verified', 'description'])\n",
    "    \n",
    "for values in end_time.values():\n",
    "    # get tweets from the API\n",
    "    tweets = client.search_recent_tweets(query=query,\n",
    "                                     start_time=start_time,\n",
    "                                     end_time=values,\n",
    "                                     tweet_fields = [\"created_at\", \"text\", \"source\"],\n",
    "                                     user_fields = [\"name\", \"username\", \"location\", \"verified\", \"description\"],\n",
    "                                     max_results = 100,\n",
    "                                     expansions='author_id'\n",
    "                                     )\n",
    "\n",
    "    # create a list of records\n",
    "    tweet_info_ls = []\n",
    "    # iterate over each tweet and corresponding user details\n",
    "    for tweet, user in zip(tweets.data, tweets.includes['users']):\n",
    "        tweet_info = {\n",
    "        'created_at': tweet.created_at,\n",
    "        'text': tweet.text,\n",
    "        'source': tweet.source,\n",
    "        'name': user.name,\n",
    "        'username': user.username,\n",
    "        'location': user.location,\n",
    "        'verified': user.verified,\n",
    "        'description': user.description\n",
    "        }\n",
    "        tweet_info_ls.append(tweet_info)\n",
    "    \n",
    "    \n",
    "    # create dataframe from the extracted records\n",
    "    tweets_df = pd.DataFrame(tweet_info_ls)\n",
    "    # display the dataframe\n",
    "    tweets_df.head()\n",
    "\n",
    "    tweets_df.to_csv('tweets_py.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5158d46",
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequests",
     "evalue": "429 Too Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2652e7ae537e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# get tweets from the API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     tweets = client.search_recent_tweets(query=query1,\n\u001b[0m\u001b[0;32m      7\u001b[0m                                      \u001b[0mstart_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                      \u001b[0mend_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36msearch_recent_tweets\u001b[1;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[0;32m   1246\u001b[0m         \"\"\"\n\u001b[0;32m   1247\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"query\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1248\u001b[1;33m         return self._make_request(\n\u001b[0m\u001b[0;32m   1249\u001b[0m             \u001b[1;34m\"GET\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"/2/tweets/search/recent\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m             endpoint_parameters=(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mrequest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         response = self.request(method, route, params=request_params,\n\u001b[0m\u001b[0;32m    127\u001b[0m                                 json=json, user_auth=user_auth)\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m    112\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_auth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTooManyRequests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTwitterServerError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTooManyRequests\u001b[0m: 429 Too Many Requests"
     ]
    }
   ],
   "source": [
    "# query to search for tweets\n",
    "query1 = \"sad lang:en -is:retweet\"\n",
    "\n",
    "for values in end_time.values():\n",
    "    # get tweets from the API\n",
    "    tweets = client.search_recent_tweets(query=query1,\n",
    "                                     start_time=start_time,\n",
    "                                     end_time=values,\n",
    "                                     tweet_fields = [\"created_at\", \"text\", \"source\"],\n",
    "                                     user_fields = [\"name\", \"username\", \"location\", \"verified\", \"description\"],\n",
    "                                     max_results = 100,\n",
    "                                     expansions='author_id'\n",
    "                                     )\n",
    "\n",
    "    # create a list of records\n",
    "    tweet_info_ls = []\n",
    "    # iterate over each tweet and corresponding user details\n",
    "    for tweet, user in zip(tweets.data, tweets.includes['users']):\n",
    "        tweet_info = {\n",
    "        'created_at': tweet.created_at,\n",
    "        'text': tweet.text,\n",
    "        'source': tweet.source,\n",
    "        'name': user.name,\n",
    "        'username': user.username,\n",
    "        'location': user.location,\n",
    "        'verified': user.verified,\n",
    "        'description': user.description\n",
    "        }\n",
    "        tweet_info_ls.append(tweet_info)\n",
    "    \n",
    "    \n",
    "    # create dataframe from the extracted records\n",
    "    tweets_df = pd.DataFrame(tweet_info_ls)\n",
    "    # display the dataframe\n",
    "    tweets_df.head()\n",
    "\n",
    "    tweets_df.to_csv('tweets_py.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b115d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to search for tweets\n",
    "query2 = \"suicide lang:en -is:retweet\"\n",
    "\n",
    "for values in end_time.values():\n",
    "    # get tweets from the API\n",
    "    tweets = client.search_recent_tweets(query=query2,\n",
    "                                     start_time=start_time,\n",
    "                                     end_time=values,\n",
    "                                     tweet_fields = [\"created_at\", \"text\", \"source\"],\n",
    "                                     user_fields = [\"name\", \"username\", \"location\", \"verified\", \"description\"],\n",
    "                                     max_results = 100,\n",
    "                                     expansions='author_id'\n",
    "                                     )\n",
    "\n",
    "    # create a list of records\n",
    "    tweet_info_ls = []\n",
    "    # iterate over each tweet and corresponding user details\n",
    "    for tweet, user in zip(tweets.data, tweets.includes['users']):\n",
    "        tweet_info = {\n",
    "        'created_at': tweet.created_at,\n",
    "        'text': tweet.text,\n",
    "        'source': tweet.source,\n",
    "        'name': user.name,\n",
    "        'username': user.username,\n",
    "        'location': user.location,\n",
    "        'verified': user.verified,\n",
    "        'description': user.description\n",
    "        }\n",
    "        tweet_info_ls.append(tweet_info)\n",
    "    \n",
    "    \n",
    "    # create dataframe from the extracted records\n",
    "    tweets_df = pd.DataFrame(tweet_info_ls)\n",
    "    # display the dataframe\n",
    "    tweets_df.head()\n",
    "\n",
    "    tweets_df.to_csv('tweets_py.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bd4db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to search for tweets\n",
    "query3 = \"stress lang:en -is:retweet\"\n",
    "\n",
    "for values in end_time.values():\n",
    "    # get tweets from the API\n",
    "    tweets = client.search_recent_tweets(query=query3,\n",
    "                                     start_time=start_time,\n",
    "                                     end_time=values,\n",
    "                                     tweet_fields = [\"created_at\", \"text\", \"source\"],\n",
    "                                     user_fields = [\"name\", \"username\", \"location\", \"verified\", \"description\"],\n",
    "                                     max_results = 100,\n",
    "                                     expansions='author_id'\n",
    "                                     )\n",
    "\n",
    "    # create a list of records\n",
    "    tweet_info_ls = []\n",
    "    # iterate over each tweet and corresponding user details\n",
    "    for tweet, user in zip(tweets.data, tweets.includes['users']):\n",
    "        tweet_info = {\n",
    "        'created_at': tweet.created_at,\n",
    "        'text': tweet.text,\n",
    "        'source': tweet.source,\n",
    "        'name': user.name,\n",
    "        'username': user.username,\n",
    "        'location': user.location,\n",
    "        'verified': user.verified,\n",
    "        'description': user.description\n",
    "        }\n",
    "        tweet_info_ls.append(tweet_info)\n",
    "    \n",
    "    \n",
    "    # create dataframe from the extracted records\n",
    "    tweets_df = pd.DataFrame(tweet_info_ls)\n",
    "    # display the dataframe\n",
    "    tweets_df.head()\n",
    "\n",
    "    tweets_df.to_csv('tweets_py.csv', mode='a', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
